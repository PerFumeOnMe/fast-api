# recommender_tf_idf.py
import pandas as pd
from app.core.utils import safe_str
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from app.core.utils import load_excel_from_s3
from app.core.config import S3_BUCKET, S3_KEY
from app.core.config import (
    TFIDF_NGRAM_RANGE,
    TFIDF_MAX_FEATURES,
    WEIGHT_CORE_KEYWORDS,
    WEIGHT_DESCRIPTION,
    WEIGHT_NOTES,
    WEIGHT_BRAND,
    WEIGHT_CONTEXT,
    BRAND_DIVERSITY_RATIO,
    NOTE_DIVERSITY_RATIO
)


class PerfumeRecommender:
    _cache = None  # ìºì‹±: í•œ ë²ˆë§Œ ë¡œë“œ

    def __init__(self, excel_path: str = None):
        if PerfumeRecommender._cache is None:
            # S3ì—ì„œ ë¡œë“œ
            PerfumeRecommender._cache = load_excel_from_s3(S3_BUCKET, S3_KEY)
        self.df = PerfumeRecommender._cache
        self.df = self.df.dropna(subset=["í–¥ìˆ˜ì´ë¦„", "í–¥ìˆ˜ í‚¤ì›Œë“œ"])
        self._prepare_documents()

    def _prepare_documents(self):
        """
        ì†ì„±ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ ë¬¸ì„œ ì¤€ë¹„
        - í•µì‹¬ ì†ì„±ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        - ìž¥ì†Œ ì†ì„± ì¶”ê°€ í™œìš©
        """
        # ì†ì„±ë³„ ê°€ì¤‘ì¹˜ ì ìš©ëœ í…ìŠ¤íŠ¸ ìƒì„±
        core_keywords = (self.df["í–¥ìˆ˜ í‚¤ì›Œë“œ"].fillna('').astype(str) + ' ') * int(WEIGHT_CORE_KEYWORDS)
        description = (self.df["í•œì¤„ì†Œê°œ"].fillna('').astype(str) + ' ') * int(WEIGHT_DESCRIPTION)
        
        note_texts = (
            (self.df["íƒ‘ ë…¸íŠ¸ ì„¤ëª…"].fillna('').astype(str) + ' ' +
             self.df["ë¯¸ë“¤ ë…¸íŠ¸ ì„¤ëª…"].fillna('').astype(str) + ' ' +
             self.df["ë² ì´ìŠ¤ ë…¸íŠ¸ ì„¤ëª…"].fillna('').astype(str) + ' ') * int(WEIGHT_NOTES)
        )
        
        brand_text = (self.df["ë¸Œëžœë“œ"].fillna('').astype(str) + ' ') * int(WEIGHT_BRAND)
        
        context_text = (
            (self.df["ì„±ë³„"].fillna('').astype(str) + ' ' +
             self.df["ê³„ì ˆ"].fillna('').astype(str) + ' ' +
             self.df["ìž¥ì†Œ"].fillna('').astype(str) + ' ') * int(WEIGHT_CONTEXT)
        )
        
        # ëª¨ë“  ì†ì„± ê²°í•©
        self.df["full_text"] = (
            core_keywords +
            description +
            note_texts +
            brand_text +
            context_text +
            self.df["íƒ‘ ë…¸íŠ¸ í‚¤ì›Œë“œ"].fillna('').astype(str) + ' ' +
            self.df["ë¯¸ë“¤ ë…¸íŠ¸ í‚¤ì›Œë“œ"].fillna('').astype(str) + ' ' +
            self.df["ë² ì´ìŠ¤ ë…¸íŠ¸ í‚¤ì›Œë“œ"].fillna('').astype(str)
        )

        self.vectorizer = TfidfVectorizer(
            ngram_range=TFIDF_NGRAM_RANGE,
            max_features=TFIDF_MAX_FEATURES
        )
        self.tfidf_matrix = self.vectorizer.fit_transform(self.df["full_text"])
        self.feature_names = self.vectorizer.get_feature_names_out()

    def _match_score(self, user_value: str, perfume_value: str, weight: float = 0.1) -> float:
        """ê°œì„ ëœ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°"""
        if pd.isna(perfume_value) or not user_value:
            return 0
        return weight if user_value.strip().lower() in str(perfume_value).strip().lower() else 0
    
    def _calculate_diversity_penalty(self, results: list, new_item: dict) -> float:
        """ë‹¤ì–‘ì„± íŽ˜ë„í‹° ê³„ì‚° (ë¸Œëžœë“œ/ë…¸íŠ¸ ì¤‘ë³µ ë°©ì§€)"""
        penalty = 0
        
        # ë¸Œëžœë“œ ë‹¤ì–‘ì„± ê²€ì‚¬
        existing_brands = [r.get('brand', '') for r in results]
        if new_item.get('brand', '') in existing_brands:
            penalty += 0.2
        
        # ë…¸íŠ¸ ê³„ì—´ ë‹¤ì–‘ì„± ê²€ì‚¬
        new_notes = (new_item.get('topNote', '') + ' ' + 
                    new_item.get('middleNote', '') + ' ' + 
                    new_item.get('baseNote', '')).lower()
        
        for result in results:
            existing_notes = (result.get('topNote', '') + ' ' + 
                            result.get('middleNote', '') + ' ' + 
                            result.get('baseNote', '')).lower()
            
            # ë…¸íŠ¸ ìœ ì‚¬ì„± ê³„ì‚° (ë‹¨ìˆœ ë¬¸ìžì—´ ë§¤ì¹­)
            if existing_notes and new_notes:
                common_words = set(existing_notes.split()) & set(new_notes.split())
                if len(common_words) > 2:  # ê³µí†µ ë‹¨ì–´ 3ê°œ ì´ìƒ
                    penalty += 0.15
        
        return penalty

    def _calculate_keyword_rarity_weights(self, user_keywords: list[str]) -> dict:
        """
        í‚¤ì›Œë“œ í¬ì†Œì„± ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
        - í¬ì†Œí•œ í‚¤ì›Œë“œì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        """
        keyword_weights = {}
        total_documents = len(self.df)
        
        for keyword in user_keywords:
            if not keyword:
                continue
                
            # í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì„œ ìˆ˜ ê³„ì‚°
            matching_count = self.df['full_text'].str.contains(
                keyword.lower(), case=False, na=False
            ).sum()
            
            if matching_count == 0:
                # ì „í˜€ ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ì›Œë“œëŠ” ìµœê³  ê°€ì¤‘ì¹˜
                keyword_weights[keyword] = 2.0
            else:
                # í¬ì†Œì„± ê³„ì‚°: (1 - ë°œìƒë¹ˆë„) * 2 + 0.5
                frequency = matching_count / total_documents
                rarity_score = max(0.5, (1 - frequency) * 2 + 0.5)
                keyword_weights[keyword] = min(2.0, rarity_score)
        
        return keyword_weights
    
    def _apply_keyword_weights(self, query: str, user_keywords: list[str]) -> str:
        """
        í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì¿¼ë¦¬ ë¬¸ìžì—´ ìƒì„±
        """
        keyword_weights = self._calculate_keyword_rarity_weights(user_keywords)
        
        weighted_query_parts = []
        for keyword in user_keywords:
            weight = keyword_weights.get(keyword, 1.0)
            # ê°€ì¤‘ì¹˜ë§Œí¼ í‚¤ì›Œë“œ ë°˜ë³µ
            repeat_count = int(weight)
            weighted_query_parts.extend([keyword] * repeat_count)
        
        return " ".join(weighted_query_parts)
    
    def _top_influential_keywords(self, user_keywords: list[str], perfume_vector) -> list[str]:
        """
        í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ë¥¼ ê³ ë ¤í•œ ì˜í–¥ë ¥ ìžˆëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ
        """
        scores = {}
        perfume_vector_array = perfume_vector.toarray().flatten()
        keyword_weights = self._calculate_keyword_rarity_weights(user_keywords)
        
        for kw in user_keywords:
            if kw in self.feature_names:
                idx = list(self.feature_names).index(kw)
                base_score = perfume_vector_array[idx]
                # í‚¤ì›Œë“œ í¬ì†Œì„± ê°€ì¤‘ì¹˜ ì ìš©
                weighted_score = base_score * keyword_weights.get(kw, 1.0)
                scores[kw] = weighted_score
        
        sorted_keywords = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [kw for kw, _ in sorted_keywords[:3]]

    def recommend(self, ambience: str, style: str, gender: str, season: str, personality: str, top_n: int = 3) -> dict:
        """
        ê°œì„ ëœ TF-IDF ì¶”ì²œ ì‹œìŠ¤í…œ
        - ë°ì´í„°ì…‹ ìž¥ì†Œ ì†ì„± ë‚´ë¶€ í™œìš©
        - ë‹¤ì–‘ì„± ê³ ë ¤ ì•Œê³ ë¦¬ì¦˜
        - ê°œì„ ëœ ë§¤ì¹­ ìŠ¤ì½”ì–´
        """
        user_keywords = [ambience, style, gender, season, personality]
        
        # í‚¤ì›Œë“œ í¬ì†Œì„± ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ì ìš©
        weighted_query = self._apply_keyword_weights(" ".join(user_keywords), user_keywords)
        print(f"ðŸŽ¯ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì ìš© - ì›ë³¸: {user_keywords}")
        print(f"ðŸŽ¯ ê°€ì¤‘ì¹˜ ì ìš© í›„: {weighted_query}")
        
        query_vec = self.vectorizer.transform([weighted_query])

        if query_vec.nnz == 0:
            print("âŒ query ë²¡í„°ê°€ 0ìž…ë‹ˆë‹¤. ìœ ì‚¬ë„ ê³„ì‚° ë¶ˆê°€")
            return {
                "average_similarity": 0,
                "results": []
            }

        cosine_sim = cosine_similarity(query_vec, self.tfidf_matrix).flatten()

        scores = []
        for i, row in self.df.iterrows():
            # ê¸°ë³¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            base_score = cosine_sim[i]
            
            # ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­ ìŠ¤ì½”ì–´ (ê°€ì¤‘ì¹˜ ì ìš©)
            gender_score = self._match_score(gender, row.get("ì„±ë³„", ""), 0.15)
            season_score = self._match_score(season, row.get("ê³„ì ˆ", ""), 0.15)
            # ë°ì´í„°ì…‹ì˜ ìž¥ì†Œ ì†ì„±ì€ TF-IDF ë²¡í„°í™”ì—ì„œ ì´ë¯¸ ë°˜ì˜ë¨
            
            final_score = base_score + gender_score + season_score
            scores.append((i, final_score))

        # ìƒìœ„ í›„ë³´êµ° ì„ ë³„ (top_n * 2 ë°°ë¥¼ ì„ ë³„í•˜ì—¬ ë‹¤ì–‘ì„± ê³ ë ¤)
        candidate_size = min(top_n * 3, len(scores))
        sorted_candidates = sorted(scores, key=lambda x: x[1], reverse=True)[:candidate_size]

        # ë‹¤ì–‘ì„± ê³ ë ¤ ì„ ë³„
        final_results = []
        for i, score in sorted_candidates:
            if len(final_results) >= top_n:
                break
                
            row = self.df.iloc[i]
            perfume_vector = self.tfidf_matrix[i]
            top_keywords = self._top_influential_keywords(user_keywords, perfume_vector)

            candidate_item = {
                "similarity": round(score, 4),
                "brand": safe_str(row.get("ë¸Œëžœë“œ", "")),
                "name": safe_str(row.get("í–¥ìˆ˜ì´ë¦„", "")),
                "topNote": safe_str(row.get("íƒ‘ ë…¸íŠ¸ í‚¤ì›Œë“œ", "")),
                "middleNote": safe_str(row.get("ë¯¸ë“¤ ë…¸íŠ¸ í‚¤ì›Œë“œ", "")),
                "baseNote": safe_str(row.get("ë² ì´ìŠ¤ ë…¸íŠ¸ í‚¤ì›Œë“œ", "")),
                "description": safe_str(row.get("í•œì¤„ì†Œê°œ", row.get("í–¥ìˆ˜ í‚¤ì›Œë“œ", ""))),
                "relatedKeywords": top_keywords,
                "imageUrl": safe_str(row.get("í–¥ìˆ˜ ì´ë¯¸ì§€", "")),
                "removebgImageUrl": safe_str(row.get("rmbg_s3_url", ""))
            }
            
            # ë‹¤ì–‘ì„± íŽ˜ë„í‹° ê³„ì‚°
            diversity_penalty = self._calculate_diversity_penalty(final_results, candidate_item)
            adjusted_score = score - diversity_penalty
            
            # ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ì„ ë³„ (ë‚˜ìœ ì „ì²´ ì ìˆ˜ì¸ ê²½ìš° ì œì™¸)
            if adjusted_score > 0.05 or len(final_results) < 2:  # ìµœì†Œ 2ê°œëŠ” ë³´ìž¥
                candidate_item["similarity"] = round(adjusted_score, 4)
                final_results.append(candidate_item)

        # ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¶”ê°€ ì±„ìš°ê¸°
        if len(final_results) < top_n:
            remaining_candidates = sorted_candidates[len(final_results):]
            for i, score in remaining_candidates[:top_n - len(final_results)]:
                row = self.df.iloc[i]
                perfume_vector = self.tfidf_matrix[i]
                top_keywords = self._top_influential_keywords(user_keywords, perfume_vector)
                
                final_results.append({
                    "similarity": round(score, 4),
                    "brand": safe_str(row.get("ë¸Œëžœë“œ", "")),
                    "name": safe_str(row.get("í–¥ìˆ˜ì´ë¦„", "")),
                    "topNote": safe_str(row.get("íƒ‘ ë…¸íŠ¸ í‚¤ì›Œë“œ", "")),
                    "middleNote": safe_str(row.get("ë¯¸ë“¤ ë…¸íŠ¸ í‚¤ì›Œë“œ", "")),
                    "baseNote": safe_str(row.get("ë² ì´ìŠ¤ ë…¸íŠ¸ í‚¤ì›Œë“œ", "")),
                    "description": safe_str(row.get("í•œì¤„ì†Œê°œ", row.get("í–¥ìˆ˜ í‚¤ì›Œë“œ", ""))),
                    "relatedKeywords": top_keywords,
                    "imageUrl": safe_str(row.get("í–¥ìˆ˜ ì´ë¯¸ì§€", "")),
                    "removebgImageUrl": safe_str(row.get("rmbg_s3_url", ""))
                })

        similarity_scores = [r["similarity"] for r in final_results]
        avg_sim = sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0

        return {
            "average_similarity": round(avg_sim, 4),
            "results": final_results
        }
